{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes_continuous.ipynb",
      "provenance": [],
      "mount_file_id": "1LAbOYPk2BKIhZAYlMQp5lAKdxYdOZjuu",
      "authorship_tag": "ABX9TyMNDe5ei4zzXbyc0WcmiuC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MustafizSaadi/DMLab/blob/main/Naive_Bayes_continuous.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a1SdjUZTukR"
      },
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "from io import StringIO\n",
        "import re\n",
        "import sys\n",
        "import math\n",
        "import statistics \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X31jVeM3UFvp"
      },
      "source": [
        "# cd /content/drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv7l_i62UKwa"
      },
      "source": [
        "def parse_csv(csv_str, columns, full_table, labels):\n",
        "  i = 0\n",
        "  tuples = csv_str.split('\\n')\n",
        "  for s in tuples:\n",
        "    data = s.split(',')\n",
        "    data = list(filter(None, data))\n",
        "    # data = data[1:]\n",
        "    if i == 0:\n",
        "      for d in data[:-1]:\n",
        "        columns.append(d)\n",
        "    elif len(data)!=0:\n",
        "      labels.append(data[len(data)-1])\n",
        "      data = [float(d) for d in data[:-1]]\n",
        "      full_table.append(data)\n",
        "    i += 1\n",
        "  return columns, full_table, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwN1HNftUVHW"
      },
      "source": [
        "def parse_csv2(csv_str):\n",
        "  attribute_dictionary = dict()\n",
        "  tuples = csv_str.split('\\n')\n",
        "  for s in tuples:\n",
        "    data = s.split(',')\n",
        "    attribute = data[0]\n",
        "    if attribute != '' :\n",
        "      attribute_dictionary[attribute] = data[1:]\n",
        "  return attribute_dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5RRV6tj-xgh"
      },
      "source": [
        "def load_dataset_wine(file_name):\n",
        "  # attribute_dictionary = dict()\n",
        "  df = pd.read_csv(file_name)\n",
        "  fixed_columns = ['class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
        "\t                'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity',\n",
        " \t                'Hue', 'OD280/OD315 of diluted wines', 'Proline' ]\n",
        "  # df.to_csv(file_name, header = fixed_columns, index=False)\n",
        "\n",
        "  # df = pd.read_csv(file_name)\n",
        "  labels = df['class'].values.tolist()\n",
        "  fixed_columns.remove('class')\n",
        "  df = df[fixed_columns]\n",
        "\n",
        "  # for column in fixed_columns:\n",
        "  #   attribute_dictionary[column] = df[column].unique()\n",
        "  #   # print(len(attribute_dictionary[column]))\n",
        "  # attribute_dictionary['class'] = np.unique(np.array(labels))\n",
        "\n",
        "  full_table = df.values.tolist()\n",
        "  # fixed_columns.append('class')\n",
        "  # print(labels)\n",
        "  return fixed_columns, full_table, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgQKY9QlXGTL"
      },
      "source": [
        "def gaussian(data, x):\n",
        "  mean = statistics.mean(data)\n",
        "  std = statistics.stdev(data)\n",
        "  if std == 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return (1/(math.sqrt(2*3.1416) * std)) * math.exp(-((x-mean)**2)/(2*std**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKyU7QXUhl3"
      },
      "source": [
        "def naive_bayes(labels, columns, database, database_labels, test):\n",
        "  max_posterior = -100\n",
        "  prediction = \"\"\n",
        "  for label in labels:\n",
        "    indices = [ind for ind in range(len(database_labels)) if database_labels[ind] == label]\n",
        "    prior_label = len(indices)/len(database_labels)\n",
        "    posterior = prior_label\n",
        "    for i in range(len(test)):\n",
        "      data = []\n",
        "      for ind in indices:\n",
        "        data.append(database[ind][i])\n",
        "      \n",
        "      posterior *= gaussian(data, test[i])\n",
        "\n",
        "    # print(label, posterior)\n",
        "    if posterior > max_posterior:\n",
        "      max_posterior = posterior \n",
        "      prediction = label\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWfr50MXUWh8",
        "outputId": "13f8c911-6f69-4144-c1a1-9c9880e3c755"
      },
      "source": [
        "# print(columns)\n",
        "# print(database)\n",
        "# print(database_labels)\n",
        "num_epochs = 10\n",
        "accuracy = 0\n",
        "precision = 0\n",
        "recall = 0\n",
        "# columns, database, database_labels, attribute_dictionary = load_dataset_mushroom('agaricus-lepiota.data')\n",
        "for i in range(num_epochs):\n",
        "  # f = open('winequality-red.csv', 'r')\n",
        "  # f = open('glass.data', 'r')\n",
        "  # columns, database, database_labels = parse_csv(f.read(-1), [], [], [])\n",
        "  # columns, database, database_labels = load_dataset_wine('wine.data')\n",
        "  f = open('Wholesale customers data.csv', 'r')\n",
        "  columns, database, database_labels = parse_csv(f.read(-1), [], [], [])\n",
        "  labels = set()\n",
        "  for label in database_labels:\n",
        "    labels.add(label)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(database, database_labels, test_size=0.2)\n",
        "  prediction = []\n",
        "  for test in X_test:\n",
        "    prediction.append(naive_bayes(labels, columns, database, database_labels, test))\n",
        "  print(prediction)\n",
        "\n",
        "  accuracy += accuracy_score(y_test, prediction)\n",
        "  precision += precision_score(y_test, prediction, average = 'macro')\n",
        "  recall += recall_score(y_test, prediction, average = 'macro')\n",
        "\n",
        "print(\"accuracy \", accuracy/num_epochs)\n",
        "print(\"precision \", precision/num_epochs)\n",
        "print(\"recall \", recall/num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1', '1', '2', '1', '1', '2', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '2', '2', '1', '2', '2', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2']\n",
            "['2', '2', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '2', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '1', '2', '1', '2', '1', '2', '1', '1']\n",
            "['1', '1', '2', '2', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '2', '1', '1', '2', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '2', '1', '2', '2', '2', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2']\n",
            "['2', '2', '2', '1', '2', '1', '1', '2', '2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '2', '2', '2', '1', '2', '2', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '2']\n",
            "['1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '2', '1', '1', '1', '1', '2', '2', '2', '2', '2', '1', '1', '1', '2', '1', '1', '2', '1', '2', '1', '2', '2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
            "['2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '2', '1', '1', '1', '2', '2', '1', '1', '2', '2', '2', '1', '2', '1', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '1', '2', '2', '2', '2', '2', '1', '2', '1', '2', '1', '1', '1', '1', '2', '1', '2', '1', '1']\n",
            "['2', '2', '2', '1', '2', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '1', '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '2', '1', '1', '1']\n",
            "['1', '2', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2', '1', '1', '1', '1', '1', '2', '2', '1', '1', '2', '1', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '2', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
            "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '2', '2', '1', '1', '2', '2', '2', '2', '2', '1', '2', '1', '1', '2', '2', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '2', '2', '2', '1', '2', '1', '1', '1', '1', '1']\n",
            "['2', '1', '1', '2', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '2', '1', '2', '2', '2', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '2', '1', '1', '2', '1', '1', '1', '2', '1', '2', '2', '2', '1', '1', '1', '2', '2', '1', '1', '1', '1', '2', '1', '1']\n",
            "accuracy  0.8999999999999998\n",
            "precision  0.8949535575126042\n",
            "recall  0.879280586556051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7bi1RYwwiN"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(database, database_labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMPN6AfHZdCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f58ae2-c6a4-4d11-f86c-fe7886ff1753"
      },
      "source": [
        "# test = [5.35,3.0,2.0,1.25]\n",
        "prediction = []\n",
        "for test in X_test:\n",
        "  prediction.append(naive_bayes(labels, columns, database, database_labels, test))\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1', '1', '1', '1', '2', '2', '2', '1', '1', '1', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '1', '2', '2', '1', '2', '2', '1', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '2', '1', '2', '1', '1', '2', '1', '2', '2', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm7kzQUty8Bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a621d4e-bd17-4b87-a599-583f481c72ea"
      },
      "source": [
        "print(accuracy_score(y_test, prediction))\n",
        "print(precision_score(y_test, prediction, average = 'macro'))\n",
        "print(recall_score(y_test, prediction, average = 'macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8977272727272727\n",
            "0.8849423193685488\n",
            "0.8773809523809524\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}